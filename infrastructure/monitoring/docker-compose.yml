# docker stack deploy --compose-file docker-compose.yml bsapp
version: "3.3"

networks:
  bsnet:
    driver: overlay
    attachable: true

volumes:
    prometheus: {}
    grafana: {}
    alertmanager: {}
    elasticsearch: {}
    portainer: {}

configs:
  caddy_config:
    file: ./caddy/Caddyfile
  dockerd_config:
    file: ./dockerd-exporter/Caddyfile
  node_rules:
    file: ./prometheus/rules/swarm_node.rules.yml
  task_rules:
    file: ./prometheus/rules/swarm_task.rules.yml
  postgres-exporter:
    file: ./postgres-exporter/queries.yaml

services:
#  dockerd-exporter:
#    image: stefanprodan/caddy
#    networks:
#      - bsnet
#    environment:
#      - DOCKER_GWBRIDGE_IP=172.18.0.1
#      - LOGSPOUT=ignore
#    configs:
#      - source: dockerd_config
#        target: /etc/caddy/Caddyfile
#    deploy:
#      mode: global
#      resources:
#        limits:
#          memory: 128M
#        reservations:
#          memory: 64M

  cadvisor:
    image: google/cadvisor
    networks:
      - bsnet
    command: -logtostderr -docker_only
    environment:
      - LOGSPOUT=ignore
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /:/rootfs:ro
      - /var/run:/var/run
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  grafana:
    image:  local/grafana-bs:2.1
    build: grafana/
    networks:
      - bsnet
#    links:
#      - "elasticsearch"
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      #- GF_SERVER_ROOT_URL=${GF_SERVER_ROOT_URL:-localhost}
      #- GF_SMTP_ENABLED=${GF_SMTP_ENABLED:-false}
      #- GF_SMTP_FROM_ADDRESS=${GF_SMTP_FROM_ADDRESS:-email}
      #- GF_SMTP_FROM_NAME=${GF_SMTP_FROM_NAME:-Grafana}
      #- GF_SMTP_HOST=${GF_SMTP_HOST:-smtp:465}
      #- GF_SMTP_USER=${GF_SMTP_USER:-email}
      #- GF_SMTP_PASSWORD=${GF_SMTP_PASSWORD:-pass}
      - LOGSPOUT=ignore
    volumes:
      - grafana:/var/lib/grafana
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  alertmanager:
    image: local/swarmprom-alertmanager:v0.14.0
    build: alertmanager/
    networks:
      - bsnet
    environment:
      - SLACK_URL=${SLACK_URL:-https://hooks.slack.com/services/url}
      - SLACK_CHANNEL=${SLACK_CHANNEL:-devops_alerts}
      - SLACK_USER=${SLACK_USER:-devops}
      - LOGSPOUT=ignore
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    volumes:
      - alertmanager:/alertmanager
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

#  unsee:
#    image: cloudflare/unsee:v0.8.0
#    networks:
#      - bsnet
#    environment:
#      - "ALERTMANAGER_URIS=default:http://alertmanager:9093"
#      - LOGSPOUT=ignore
#    deploy:
#      mode: replicated
#      replicas: 1

  node-exporter:
    image: local/swarmprom-node-exporter:v0.15.2
    build:  node-exporter/
    networks:
      - bsnet
    environment:
      - NODE_ID={{.Node.ID}}
      - LOGSPOUT=ignore
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /etc/hostname:/etc/nodename
    command:
      - '--path.sysfs=/host/sys'
      - '--path.procfs=/host/proc'
      - '--collector.textfile.directory=/etc/node-exporter/'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
      # no collectors are explicitely enabled here, because the defaults are just fine,
      # see https://github.com/prometheus/node_exporter
      # disable ipvs collector because it barfs the node-exporter logs full with errors on my centos 7 vm's
      - '--no-collector.ipvs'
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  prometheus:
    image: local/swarmprom-prometheus:latest
    build: prometheus/
    networks:
      - bsnet
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention=24h'
    environment:
      - LOGSPOUT=ignore
    volumes:
      - prometheus:/prometheus
    configs:
      - source: node_rules
        target: /etc/prometheus/swarm_node.rules.yml
      - source: task_rules
        target: /etc/prometheus/swarm_task.rules.yml
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 128M

  caddy:
    image: stefanprodan/caddy
    ports:
      - "3000:3000"
      - "9090:9090"
      - "9093:9093"
      - "9094:9094"
    networks:
      - bsnet
    environment:
      - ADMIN_USER=${ADMIN_USER:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-password}
      - LOGSPOUT=ignore
    configs:
      - source: caddy_config
        target: /etc/caddy/Caddyfile
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 1s
      retries: 5

  kibana:
    image: kibana
    links:
      - "elasticsearch"
    environment:
      - LOGSPOUT=ignore
    ports:
      - "5601:5601"
    networks:
      - bsnet

#   networks:
#  fluentd:
#    build: fluentd #build first
#    image: local/fluentd-bs
#    hostname: "node-{{.Node.Hostname}}"
#    volumes:
#      - /var/logs:/var/logs
#    links:
#     - "elasticsearch"
#    ports:
#      - "24224:24224"
#      - "24224:24224/udp"
#    deploy:
#      mode: global
#    networks:
#     - bsnet

  logstash:
    build: logstash
    image: local/logstash-bs
    hostname: logstash
    networks:
      - bsnet
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 512M
      placement:
        constraints:
          - node.role == manager
    environment:
      - LOGSPOUT=ignore

  logspout:
    image: "gliderlabs/logspout:master"
    deploy:
      mode: global
    command: 'syslog+udp://logstash:5000?filter.name=*_app*,syslog+udp://logstash:5001?filter.name=*_rabbitmq*'
    links:
     - "logstash"
    networks:
      - bsnet
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    environment:
     - DEBUG=true
     - LOGSPOUT=ignore
     - MULTILINE_MATCH=last
     - MULTILINE_PATTERN=%{TIMESTAMP_ISO8601:date}
    depends_on:
      - logstash

  elasticsearch:
   image: elasticsearch
   expose:
     - 9200
   volumes:
     - elasticsearch:/usr/share/elasticsearch/data
   environment:
     - cluster.name=docker-cluster
     - bootstrap.memory_lock=true
     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
     - LOGSPOUT=ignore
   ulimits:
     memlock:
       soft: -1
       hard: -1
     nofile:
       soft: 65536
       hard: 65536
   deploy:
     mode: replicated
     replicas: 1
     placement:
       constraints:
         - node.role == manager
     resources:
       limits:
         memory: 1G
   ports:
     - "9200:9200"
   networks:
    - bsnet

#  postgres-exporter:
#    image: "wrouesnel/postgres_exporter"
#    extra_hosts:
#     - "postgresdb:172.17.0.1"
#    command: --extend.query-path=/queries.yaml
#    configs:
#      - source: postgres-exporter
#        target: /queries.yaml
#    deploy:
#     mode: replicated
#     replicas: 1
#     placement:
#        constraints:
#          - node.role == manager
#    networks:
#      - bsnet
#    environment:
#     - DATA_SOURCE_NAME=postgresql://login:pass@postgresdb:5432/?sslmode=disable
#     - LOGSPOUT=ignore
#    depends_on:
#      - prometheus

  portainer:
    image: portainer/portainer
    ports:
      - "9000:9000"
    environment:
     - LOGSPOUT=ignore
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
    networks:
      - bsnet
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - portainer:/data

#  registry:
#    image: registry:2
#    ports:
#      - target: 5000
#        published: 5000
#        protocol: tcp
#        mode: host
#    environment:
#     - LOGSPOUT=ignore
#    deploy:
#      replicas: 1
#      placement:
#        constraints: [node.role == manager]
#    networks:
#      - bsnet